{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_21RVchzHKvL"},"outputs":[],"source":["import spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5yQsw9CHSSW"},"outputs":[],"source":["nlp=spacy.blank('en')\n","doc=nlp(\"I love eating bread and coffee. Kevin likes tea, on the other hand sidney likes hot milk\")\n","for tokens in doc:\n","  print(tokens)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ldXJifCHhVr"},"outputs":[],"source":["doc=nlp('It all costs $300')\n","doc[3].is_currency\n","for tokens in doc:\n","  print(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1718694468508,"user":{"displayName":"Brian Rono","userId":"01630341591177302091"},"user_tz":-180},"id":"Su04lXQuI1A8","outputId":"a99f24f8-a8a0-4758-c1ed-f9ff76fd9cf9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Name     age      email\\njohn      48      john@gmail.com\\nkevin     45        kevin@gmail.com\\ndennis    43        dennis@gmail.com \\nrono       56        RONO@GMAIL.com'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["with open('/content/student files.txt') as f:\n","  text=f.readlines()\n","text\n","text=''.join(text)\n","text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1718694594254,"user":{"displayName":"Brian Rono","userId":"01630341591177302091"},"user_tz":-180},"id":"t1a8UJf4LIj7","outputId":"710a9973-a117-490b-c22e-fbba26e1dd33"},"outputs":[{"name":"stdout","output_type":"stream","text":["[john@gmail.com, kevin@gmail.com, dennis@gmail.com, RONO@GMAIL.com]\n"]}],"source":["doc=nlp(text)\n","email=[]\n","for token in doc:\n","  if token.like_email:\n","    email.append(token)\n","print(email)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9vaWW_2MG3f"},"outputs":[],"source":["nlp.add_pipe('sentencizer')\n","text=(\"'Houdini' is a song by American rapper Eminem. It was released on May 31, 2024, as the lead single from his upcoming twelfth studio album The Death of Slim Shady (Coup de Grâce). The song interpolates multiple previous Eminem works and 'Abracadabra'by the Steve Miller Band, and contains various references to pop culture. Released alongside an accompanying music video, 'Houdini' debuted at number 1 on the Billboard Global 200 and also topped the charts in Australia, Austria, Canada, Iceland, Latvia, Luxembourg, New Zealand, Norway, Portugal, South Africa, Switzerland, and the United Kingdom. It additionally has reached the top ten of the charts in the Czech Republic, Denmark, Finland, Germany, Hungary, Ireland, Israel, Lithuania, the Netherlands, Romania, Slovakia, Sweden, and the United States.\")\n","doc=nlp(text)\n","for sents in doc.sents:\n","  print(sents)\n"]},{"cell_type":"markdown","metadata":{"id":"GtuhKcR5NwRg"},"source":["Exercise\n","(1) Think stats is a free book to study statistics (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n","\n","This book has references to many websites from where you can download free datasets. You are an NLP engineer working for some company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from this book and you want to grab all urls from this paragraph using spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1718696202824,"user":{"displayName":"Brian Rono","userId":"01630341591177302091"},"user_tz":-180},"id":"upsZSVNUN2ba","outputId":"6e2fabb0-282b-4ce8-db94-6a84f8d932f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[http://www.data.gov/, http://www.science, http://data.gov.uk/., http://www3.norc.org/gss+website/, http://www.europeansocialsurvey.org/.]\n"]}],"source":["text='''\n","Look for data to help you address the question. Governments are good\n","sources because data from public research is often freely available. Good\n","places to start include http://www.data.gov/, and http://www.science.\n","gov/, and in the United Kingdom, http://data.gov.uk/.\n","Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/,\n","and the European Social Survey at http://www.europeansocialsurvey.org/.\n","'''\n","\n","# TODO: Write code here\n","# Hint: token has an attribute that can be used to detect a url\n","doc=nlp(text)\n","url=[]\n","for token in doc:\n","  if token.like_url:\n","    url.append(token)\n","print(url)"]},{"cell_type":"markdown","metadata":{"id":"D2i4HMd1N7TG"},"source":["(2) Extract all money transaction from below sentence along with currency. Output should be,\n","\n","two $\n","\n","500 €"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNnDkKHVT0dq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Hd6eNmNN8YP"},"outputs":[],"source":["transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n","\n","# TODO: Write code here\n","# Hint: Use token.i for the index of a token and token.is_currency for currencysymbol detection\n","doc=nlp(transactions)\n","for token in doc:\n","  if token.is_currency:\n","    print(doc[token.i -1 : token.i +1 ])"]},{"cell_type":"markdown","metadata":{"id":"eMAMjD7cW88Q"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1718702751763,"user":{"displayName":"Brian Rono","userId":"01630341591177302091"},"user_tz":-180},"id":"zCXMRyepTfyq","outputId":"31483a62-40ee-4064-fbe5-0d8d7fee040f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['eating', 'training', 'sleeping', 'watering'] | eat\n","['eating', 'training', 'sleeping', 'watering'] | train\n","['eating', 'training', 'sleeping', 'watering'] | sleep\n","['eating', 'training', 'sleeping', 'watering'] | water\n"]}],"source":["#Stemming in NLTK\n","from nltk.stem import PorterStemmer\n","stemmer=PorterStemmer()\n","words=['eating','training','sleeping','watering']\n","for word in  words:\n"," print(words,'|',stemmer.stem(word))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OdCVR-v4sbXe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8PI-_UZpNaZ"},"outputs":[],"source":["#lemmatisation in spacy\n","nlp=spacy.load('en_core_web_sm')\n","text=nlp('Yesterday he ate a bad of chips and now after entering the building he is eating another bag of the same chips')\n","for words in text:\n","  print(words,'|',words.lemma_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1036,"status":"ok","timestamp":1718709211639,"user":{"displayName":"Brian Rono","userId":"01630341591177302091"},"user_tz":-180},"id":"ZeaKFHWGtlV_","outputId":"d43d9e17-3561-43af-c146-4124715aa13a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Yesterday | NOUN | noun | NN | npadvmod\n","he | PRON | pronoun | PRP | nsubj\n","ate | VERB | verb | VBD | ROOT\n","a | DET | determiner | DT | det\n","bad | NOUN | noun | NN | dobj\n","of | ADP | adposition | IN | prep\n","chips | NOUN | noun | NNS | pobj\n","and | CCONJ | coordinating conjunction | CC | cc\n","now | ADV | adverb | RB | advmod\n","after | ADP | adposition | IN | prep\n","entering | VERB | verb | VBG | pcomp\n","the | DET | determiner | DT | det\n","building | NOUN | noun | NN | dobj\n","he | PRON | pronoun | PRP | nsubj\n","is | AUX | auxiliary | VBZ | aux\n","eating | VERB | verb | VBG | relcl\n","another | DET | determiner | DT | det\n","bag | NOUN | noun | NN | dobj\n","of | ADP | adposition | IN | prep\n","the | DET | determiner | DT | det\n","same | ADJ | adjective | JJ | amod\n","chips | NOUN | noun | NNS | pobj\n"]}],"source":["#part of speech tagging\n","for words in text:\n","  print(words,'|',words.pos_,'|',spacy.explain(words.pos_),'|', words.tag_,'|', words.dep_)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMdwA1eFwepPIemPT7FirWZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
